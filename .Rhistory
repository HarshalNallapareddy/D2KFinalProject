View(binary_3150)
View(binary_3150)
rm(list=ls())
convert_to_binary <- function(n) {
if(n > 1) {
convert_to_binary(as.integer(n/2))
}
cat(n %% 2)
}
convert_to_binary(30)
binary_APMA3150 <- function(x) {
if(n > 1) {
binary_APMA3150(as.integer(x/2))
}
cat(x %% 2)
}
binary_APMA3150(30)
binary_APMA3150(30)
binary_APMA3150(30)
View(convert_to_binary)
rm(list=ls())
binary_APMA3150(30)
function(n) {
if(n > 1) {
convert_to_binary(as.integer(n/2))
}
cat(n %% 2)
}
binary_APMA3150(30)
binary_APMA3150(30)
binary_APMA3150 <- function(x) {
if(x > 1) {
binary_APMA3150(as.integer(x/2))
}
cat(x %% 2)
}
binary_APMA3150(30)
knitr::opts_chunk$set(echo = TRUE)
rivers
head(rivers)
help(rivers) # prints (in a separate window) description of data set rivers
class(rivers)
str(rivers)
dim(rivers) # rivers is a vector, not a matrix
length(rivers)
library(MASS) # accesses the MASS library (part of default distribution of R)
data(geyser) # geyser is a data set in MASS
help(geyser) # help is displayed in a separate window.
geyser
dim(geyser) # geyser is a matrix with 299 rows and 2 columns
names(geyser)
colnames(geyser)
library('UsingR')
data(exec.pay)
exec.pay
exec.pay[2]
# Type your code here, and Knit.
exec.pay[-188]
# Type your code here, and Knit.
exec.pay[2]
# Type your code here, and Knit.
exec.pay[1:9]
# Type your code here, and Knit.
# exec.pay.adjusted <-
exec.pay.adjusted <- exec.pay * 1.5
# Type your code here, and Knit.
range(exec.pay.adjusted)
# Type your code here, and Knit.
# Hint: You may use a function from "which()" series.
which(exec.pay.adjusted=range(exec.pay.adjusted[2])
# Type your code here, and Knit.
# Hint: You may use a function from "which()" series.
which(exec.pay.adjusted=range(exec.pay.adjusted[2]))
# Type your code here, and Knit.
# Hint: You may use a function from "which()" series.
which(exec.pay.adjusted==range(exec.pay.adjusted[2]))
# Type your code here, and Knit.
range(exec.pay.adjusted)
data <- c(38, 43, 48, 61, 47, 24, 29, 48, 59, 24, 40, 27)
z_scores <- (data-mean(data))/sd(data)
z_scores
if (num == 2) {
TRUE
} else if (any(num %% 2:(num-1) == 0)) {
FALSE
} else {
TRUE
}
isprime <- function(num) {
if (num == 2) {
TRUE
} else if (any(num %% 2:(num-1) == 0)) {
FALSE
} else {
TRUE
}
}
isprime(4)
isprime <- function(x) {
if (x == 2) {
TRUE
} else if (any(x %% 2:(x-1) == 0)) {
FALSE
} else {
TRUE
}
}
isprime(7)
isprime(1)
isprime(648391)
isprime(648397)
cut(bumpers, c(0, 1000, 2000, 3000, 4000))
library(UsingR)
load(bumbers)
library.load(bumbers)
library(MASS)
par(mfrow=c(2,2))
hist(Cars93$Price)
hist(Cars93$MPG.highway)
qqnorm(Cars93$Price)
qqline(Cars93$Price)
qqnorm(Cars93$MPG.highway)
qqline(Cars93$MPG.highway)
skewFunction <- function(x) {
n <- length(x) # Number of observations
mean_x <- mean(x) # Mean of observations
s <- sd(x) # Standard deviation of observations
# Compute the skewness
skewness <- (n / ((n-1) * (n-2))) * sum(((x - mean_x) / s)^3)
return(skewness)
}
skewFunction(Cars93$Price)
skewFunction(Cars93$MPG.highway)
View(skewFunction)
install.packages("e1071, dep = TRUE")
skewness(Cars93$Price)
library(e1071)
install.packages("e1071, dep = TRUE")
library(e1071)
install.packages("e1071", dep = TRUE)
library(e1071)
library(UsingR)
module.load(UsingR)
data("nym.2002")
force(nym.2002)
View(nym.2002)
View(nym.2002)
View(nym.2002)
View(nym.2002)
cor(nym.2002$age, nym.2002$time)
cor(nym.2002$age, nym.2002$time), method = "spearman"]
cor(nym.2002$age, nym.2002$time, method = "spearman")
cor(log(nym.2002$age), log(nym.2002$time), method = "spearman")
library(ggplot2)
load(ggplot2)
library(ggplot2)
load(ggplot2)
library(UsingR)
data(mtcars)
force(mtcars)
View(mtcars)
View(mtcars)
ggplot2(mtcars)
ggplot(mtcars)
ggplot(mtcars$mpg, mtcars$gear)
p <- ggplot(mtcars, aes(x=mpg, y=gear)) +
geom_boxplot()
View(p)
View(p)
p <- ggplot(mtcars, aes(x=gear, y=mpg)) +
geom_boxplot()
View(p)
View(p)
ggplot(mtcars, aes(x=gear, y=mpg)) +
geom_boxplot()
ggplot(mtcars, aes(x=factor(gear), y=mpg)) +
geom_boxplot()
ggplot(mtcars, aes(x=factor(gear), y=mpg)) +
geom_boxplot() +
labs(x = "Number of Gears", y = "Miles per Gallon") +
+     ggtitle("Boxplots of Miles per Gallon by Number of Gears")
> # Create the boxplot
ggplot(mtcars, aes(x = factor(gear), y = mpg)) +
geom_boxplot() +
labs(x = "Number of Gears", y = "Miles per Gallon") +
ggtitle("Boxplots of Miles per Gallon by Number of Gears")
ggplot(mtcars, aes(x = wt, y = mpg)) +
geom_point() +  # Scatterplot
geom_smooth(method = "lm", se = FALSE) +  # Add trend line without confidence interval
labs(x = "Weight", y = "Miles per Gallon") +
ggtitle("Scatterplot of Miles per Gallon vs. Weight with Trend Line")
sample(1:6, 10, replace = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Type your code here, and Knit.
par(mfrow = c(2,3))
for (i in 1:6)
barplot(UCBAdmissions[,,i], legend.text=T,  main = paste("Dept", LETTERS[i], sep = " "))
par(mfcol = c(1,2))
# Type your code here, and Knit.
# Part 1
admit_by_gender <- margin.table(UCBAdmissions, margin = c(1, 2))
barplot(admit_by_gender, col = c("blue", "red"),
legend = TRUE, names.arg = c("Admitted", "Rejected"),
main = "Admission Proportion by Gender",
xlab = "Gender", ylab = "Count")
# Part 2
admit_by_status <- margin.table(UCBAdmissions, margin = 2)
barplot(admit_by_status, col = c("green", "orange"),
legend = TRUE, names.arg = c("Male", "Female"),
main = "Admission Proportion by Status",
xlab = "Admission Status", ylab = "Count")
p_value
from scipy.stats import norm
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", ???), rep("incorrect", ???)))
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", ???), rep("incorrect", ???)))
back = factor(c(rep("correct", ???), rep("incorrect", ???))
)
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", ???), rep("incorrect", ???)))
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
inference(back, est = "proportion", type = "ht", method = "simulation", success = "correct", null = 0.1, alternative = "greater", nsim = 100)
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
inference(back, est = "proportion", type = "ht", method = "simulation", success = "yes", null = 0.5, alternative = "greater", nsim = 100)
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
inference(back, est = "proportion", type = "ht", method = "simulation", success = "correct", null = 0.5, alternative = "greater", nsim = 100)
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
inference(back, est = "proportion", type = "ht", method = "simulation", success = "correct", null = 0.1, alternative = "greater", nsim = 100)
inference(back, est = "proportion", type = "ht", method = "simulation", success = "correct", null = 10/11, alternative = "greater", nsim = 100)
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
inference(back, est = "proportion", type = "ht", method = "simulation", success = "correct", null = 0.101010, alternative = "greater", nsim = 100)
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
inference(back, est = "proportion", type = "ht", method = "simulation", success = "correct", null = 0.909090, alternative = "greater", nsim = 100)
source("http://bit.ly/dasi_inference")
back = factor(c(rep("correct", 10), rep("incorrect", 1)))
inference(back, est = "proportion", type = "ht", method = "simulation", success = "correct", null = 0.1, alternative = "greater", nsim = 100)
pchisq(31.68, 2, lower.tail = FALSE)
pchisq(31.68, 2, lower.tail = FALSE)
pt(2.201, df=429), lower.tail = TRUE)
library(UsingR)
data(mom_hs)
pt(2.201, df=429), lower.tail = TRUE)
library(APMA3150)
data(mom_hs)
pt(2.201, df=429), lower.tail = TRUE)
rm(list = ls())
library (tidyverse)
install.packages("tidyverse")
library (tidyverse)
library(readr)
draft_combine_stats <- read_csv("Downloads/archive (2)/csv/draft_combine_stats.csv")
View(draft_combine_stats)
library(readr)
draft_history <- read_csv("Downloads/archive (2)/csv/draft_history.csv")
View(draft_history)
summary(draft_combine_stats)
View(draft_combine_stats)
summary(draft_combine_stats)
# Assuming 'combine_data' is your dataframe
combine_data <- combine_data %>%
filter(player_id != -1) %>%
mutate_at(vars(height_wo_shoes, height_w_shoes, weight, wingspan, standing_reach, hand_length, hand_width, standing_vertical_leap, max_vertical_leap, lane_agility_time, modified_lane_agility_time, three_quarter_sprint, bench_press),
list(~ as.numeric(as.character(.))))
# Assuming 'combine_data' is your dataframe
combine_data <- draft_combine_data %>%
filter(player_id != -1) %>%
mutate_at(vars(height_wo_shoes, height_w_shoes, weight, wingspan, standing_reach, hand_length, hand_width, standing_vertical_leap, max_vertical_leap, lane_agility_time, modified_lane_agility_time, three_quarter_sprint, bench_press),
list(~ as.numeric(as.character(.))))
# Assuming 'combine_data' is your dataframe
combine_data <- draft_combine_stats %>%
filter(player_id != -1) %>%
mutate_at(vars(height_wo_shoes, height_w_shoes, weight, wingspan, standing_reach, hand_length, hand_width, standing_vertical_leap, max_vertical_leap, lane_agility_time, modified_lane_agility_time, three_quarter_sprint, bench_press),
list(~ as.numeric(as.character(.))))
# Assuming 'combine_data' is your dataframe
combine_data <- draft_combine_stats %>%
filter(player_id != -1) %>%
mutate_at(vars(height_wo_shoes, height_w_shoes, weight, wingspan, standing_reach, hand_length, hand_width, standing_vertical_leap, max_vertical_leap, lane_agility_time, modified_lane_agility_time, three_quarter_sprint, bench_press),
list(~ as.numeric(as.character(.))))
ggplot(combine_data, aes(x = wingspan, y = max_vertical_leap)) +
geom_point(na.rm = TRUE) +
geom_smooth(method = "lm", na.rm = TRUE) +
labs(title = "Wingspan vs. Max Vertical Leap", x = "Wingspan (inches)", y = "Max Vertical Leap (inches)")
# Simple linear regression model
model <- lm(max_vertical_leap ~ height_wo_shoes + weight + wingspan, data = combine_data, na.action = na.exclude)
summary(model)
par(mfrow = c(2,2))
plot(model)
model_refined <- lm(max_vertical_leap ~ height_wo_shoes + weight + wingspan, data = combine_data %>% filter(!player_id %in% c(IDs_of_outliers)), na.action = na.exclude)
library (tidyverse)
# Calculate standardized residuals
combine_data$std_residuals <- rstandard(model)
# Find the Cook's distance for each observation
combine_data$cooks_distance <- cooks.distance(model)
# Identify outliers as observations with a standardized residual greater than 2 or less than -2
outlier_ids <- combine_data %>%
filter(abs(std_residuals) > 2) %>%
pull(player_id)
# Optionally, you can also look for high leverage points
high_leverage_ids <- combine_data %>%
filter(cooks_distance > (4 / nrow(combine_data))) %>%
pull(player_id)
# Combine the lists if you want to exclude both outliers and high leverage points
IDs_of_outliers <- union(outlier_ids, high_leverage_ids)
par(mfrow = c(2,2))
plot(model)
# Calculate standardized residuals
combine_data$std_residuals <- rstandard(model)
# Find the Cook's distance for each observation
combine_data$cooks_distance <- cooks.distance(model)
# Identify outliers as observations with a standardized residual greater than 2 or less than -2
outlier_ids <- combine_data %>%
filter(abs(std_residuals) > 2) %>%
pull(player_id)
# Optionally, you can also look for high leverage points
high_leverage_ids <- combine_data %>%
filter(cooks_distance > (4 / nrow(combine_data))) %>%
pull(player_id)
# Combine the lists if you want to exclude both outliers and high leverage points
IDs_of_outliers <- union(outlier_ids, high_leverage_ids)
library (tidyverse)
summary(draft_combine_stats)
# Assuming 'combine_data' is your dataframe
combine_data <- draft_combine_stats %>%
filter(player_id != -1) %>%
mutate_at(vars(height_wo_shoes, height_w_shoes, weight, wingspan, standing_reach, hand_length, hand_width, standing_vertical_leap, max_vertical_leap, lane_agility_time, modified_lane_agility_time, three_quarter_sprint, bench_press),
list(~ as.numeric(as.character(.))))
ggplot(combine_data, aes(x = wingspan, y = max_vertical_leap)) +
geom_point(na.rm = TRUE) +
geom_smooth(method = "lm", na.rm = TRUE) +
labs(title = "Wingspan vs. Max Vertical Leap", x = "Wingspan (inches)", y = "Max Vertical Leap (inches)")
# Simple linear regression model
model <- lm(max_vertical_leap ~ height_wo_shoes + weight + wingspan, data = combine_data, na.action = na.exclude)
summary(model)
par(mfrow = c(2,2))
plot(model)
model_refined <- lm(max_vertical_leap ~ height_wo_shoes + weight + wingspan,
data = combine_data %>% filter(!player_id %in% IDs_of_outliers),
na.action = na.exclude)
```{r setup, include=FALSE}
```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(caret)
install.packages("caret")
install.packages("corrplot")
install.packages("randomForest")
library(tidyverse)
library(caret)
library(corrplot)
library(randomForest)
rm(list = ls())
library(readr)
draft_combine_stats <- read_csv("Downloads/archive (2)/csv/draft_combine_stats.csv")
View(draft_combine_stats)
library(readr)
draft_history <- read_csv("Downloads/archive (2)/csv/draft_history.csv")
View(draft_history)
combined_data <- merge(draft_combine_stats, draft_history, by=c("player_name", "season"), all=TRUE)
View(combined_data)
View(combined_data)
View(combined_data)
View(draft_combine_stats)
View(draft_history)
View(draft_combine_stats)
# Handling missing values, normalizing, and encoding variables
combined_data <- combined_data %>%
mutate(across(where(is.numeric), ~ replace_na(., mean(., na.rm = TRUE))))
summary(combined_data)
ggplot(data = combined_data, aes(x = wingspan, y = draft_pick)) + geom_point()
View(combined_data)
rm(list = ls())
library(readr)
draft_combine_stats <- read_csv("Downloads/archive (2)/csv/draft_combine_stats.csv")
View(draft_combine_stats)
library(readr)
draft_history <- read_csv("Downloads/archive (2)/csv/draft_history.csv")
View(draft_history)
View(draft_combine_stats)
View(draft_history)
View(draft_combine_stats)
View(draft_history)
cd desktop
cd Desktop
View(draft_combine_stats)
View(draft_combine_stats)
View(draft_history)
View(draft_history)
View(draft_combine_stats)
View(draft_history)
data(draft_combine_stats)
ls
ls
ls
stats <- read.csv("draft_combine_stats")
stats <- read.csv("csv/draft_combine_stats")
setwd("~/Desktop/D2KFinalProject")
stats <- read.csv("csv/draft_combine_stats")
stats <- read.csv("csv/draft_combine_stats")
stats <- read.csv("csv/draft_combine_stats")
stats <- read.csv("csv/draft_combine_stats.csv")
View(draft_combine_stats)
View(draft_history)
View(draft_combine_stats)
View(draft_history)
View(draft_combine_stats)
stats <- read.csv("csv/draft_combine_stats")
stats <- read.csv("csv/draft_combine_stats.csv")
history <- read.csv("csv/draft_history.csv")
summarise(stats)
summarise(stats)
summary(stats)
summary(history)
summary(stats)
summary(history)
View(draft_combine_stats)
stats <- stats[, 1:24]
summary(stats)
stats <- stats[, 1:24]
stats$person_id <- draft_combine_stats$player_id
stats$player_id <- NULL
View(draft_combine_stats)
View(stats)
View(history)
statss$seasons <- as.factor(draft_combine_stats$season)
stats$seasons <- as.factor(draft_combine_stats$season)
history$seasons <- as.factor(draft_history$season)
View(stats)
stats <- read.csv("csv/draft_combine_stats.csv")
history <- read.csv("csv/draft_history.csv")
View(stats)
summary(stats)
summary(history)
stats <- stats[, 1:24]
stats$person_id <- draft_combine_stats$player_id
stats$player_id <- NULL
stats$seasons <- as.factor(draft_combine_stats$season)
history$seasons <- as.factor(draft_history$season)
stats <- read.csv("csv/draft_combine_stats.csv")
history <- read.csv("csv/draft_history.csv")
summary(stats)
summary(history)
stats <- stats[, 1:24]
stats$person_id <- draft_combine_stats$player_id
stats$player_id <- NULL
stats$season <- as.factor(draft_combine_stats$season)
history$season <- as.factor(draft_history$season)
View(stats)
View(history)
stats <- read.csv("csv/draft_combine_stats.csv")
history <- read.csv("csv/draft_history.csv")
summary(stats)
summary(history)
stats <- stats[, 1:24]
stats$person_id <- draft_combine_stats$player_id
stats$player_id <- NULL
stats$season <- as.factor(draft_combine_stats$season)
history$season <- as.factor(draft_history$season)
stats <- subset(stats, person_id %in% history$person_id & season %in% history$season)
history <- subset(history, person_id %in% stats$person_id & season %in% stats$season)
history <- history[order(history$draft_year, decreasing = TRUE), ]
View(draft_combine_stats)
# Load necessary library
library(dplyr)
# Read the CSV files into data frames
combine_stats <- read.csv("csv/draft_combine_stats.csv")
history <- read.csv("csv/draft_history.csv")
# Select columns from draft_combine_stats up to bench press
combine_stats <- combine_stats %>% select(player_id, season, everything())
# Find the index of the 'bench_press' column
bench_press_index <- which(names(combine_stats) == "bench_press")
# Keep only the columns up to 'bench_press'
combine_stats <- combine_stats[, 1:bench_press_index]
# Merge the datasets based on player_id matching person_id and season
merged_data <- merge(combine_stats, history, by.x = c("player_id", "season"), by.y = c("person_id", "season"))
# Write the merged data to a new CSV file
write.csv(merged_data, "path/to/your/merged_data.csv", row.names = FALSE)
# Load necessary library
library(dplyr)
# Read the CSV files into data frames
combine_stats <- read.csv("csv/draft_combine_stats.csv")
history <- read.csv("csv/draft_history.csv")
# Select columns from draft_combine_stats up to bench press
combine_stats <- combine_stats %>% select(player_id, season, everything())
# Find the index of the 'bench_press' column
bench_press_index <- which(names(combine_stats) == "bench_press")
# Keep only the columns up to 'bench_press'
combine_stats <- combine_stats[, 1:bench_press_index]
# Merge the datasets based on player_id matching person_id and season
merged_data <- merge(combine_stats, history, by.x = c("player_id", "season"), by.y = c("person_id", "season"))
# Write the merged data to a new CSV file
write.csv(merged_data, "csv/merged_data.csv", row.names = FALSE)
View(merged_data)
rm(list = ls())
library(dplyr)
combine_stats <- read.csv("csv/draft_combine_stats.csv")
history <- read.csv("csv/draft_history.csv")
combine_stats <- combine_stats %>% select(player_id, season, everything())
bench_press_index <- which(names(combine_stats) == "bench_press")
combine_stats <- combine_stats[, 1:bench_press_index]
merged_data <- merge(combine_stats, history, by.x = c("player_id", "season"), by.y = c("person_id", "season"))
write.csv(merged_data, "csv/merged_data.csv", row.names = FALSE)
View(merged_data)
git status
git status
